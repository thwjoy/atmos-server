{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dtw-python in /opt/anaconda3/envs/test_speech/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/test_speech/lib/python3.10/site-packages (from dtw-python) (1.14.1)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /opt/anaconda3/envs/test_speech/lib/python3.10/site-packages (from dtw-python) (2.0.2)\n",
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Install Whisper from GitHub repository\n",
    "!pip install dtw-python\n",
    "\n",
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import urllib\n",
    "import tarfile\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.ticker as ticker\n",
    "from scipy.io import wavfile\n",
    "from tqdm.notebook import tqdm\n",
    "from dtw import dtw\n",
    "from whisper.tokenizer import get_tokenizer\n",
    "from scipy.ndimage import median_filter\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_colwidth = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected language: English (en_us)\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "languages = {\"af_za\": \"Afrikaans\", \"am_et\": \"Amharic\", \"ar_eg\": \"Arabic\", \"as_in\": \"Assamese\", \"az_az\": \"Azerbaijani\", \"be_by\": \"Belarusian\", \"bg_bg\": \"Bulgarian\", \"bn_in\": \"Bengali\", \"bs_ba\": \"Bosnian\", \"ca_es\": \"Catalan\", \"cmn_hans_cn\": \"Chinese\", \"cs_cz\": \"Czech\", \"cy_gb\": \"Welsh\", \"da_dk\": \"Danish\", \"de_de\": \"German\", \"el_gr\": \"Greek\", \"en_us\": \"English\", \"es_419\": \"Spanish\", \"et_ee\": \"Estonian\", \"fa_ir\": \"Persian\", \"fi_fi\": \"Finnish\", \"fil_ph\": \"Tagalog\", \"fr_fr\": \"French\", \"gl_es\": \"Galician\", \"gu_in\": \"Gujarati\", \"ha_ng\": \"Hausa\", \"he_il\": \"Hebrew\", \"hi_in\": \"Hindi\", \"hr_hr\": \"Croatian\", \"hu_hu\": \"Hungarian\", \"hy_am\": \"Armenian\", \"id_id\": \"Indonesian\", \"is_is\": \"Icelandic\", \"it_it\": \"Italian\", \"ja_jp\": \"Japanese\", \"jv_id\": \"Javanese\", \"ka_ge\": \"Georgian\", \"kk_kz\": \"Kazakh\", \"km_kh\": \"Khmer\", \"kn_in\": \"Kannada\", \"ko_kr\": \"Korean\", \"lb_lu\": \"Luxembourgish\", \"ln_cd\": \"Lingala\", \"lo_la\": \"Lao\", \"lt_lt\": \"Lithuanian\", \"lv_lv\": \"Latvian\", \"mi_nz\": \"Maori\", \"mk_mk\": \"Macedonian\", \"ml_in\": \"Malayalam\", \"mn_mn\": \"Mongolian\", \"mr_in\": \"Marathi\", \"ms_my\": \"Malay\", \"mt_mt\": \"Maltese\", \"my_mm\": \"Myanmar\", \"nb_no\": \"Norwegian\", \"ne_np\": \"Nepali\", \"nl_nl\": \"Dutch\", \"oc_fr\": \"Occitan\", \"pa_in\": \"Punjabi\", \"pl_pl\": \"Polish\", \"ps_af\": \"Pashto\", \"pt_br\": \"Portuguese\", \"ro_ro\": \"Romanian\", \"ru_ru\": \"Russian\", \"sd_in\": \"Sindhi\", \"sk_sk\": \"Slovak\", \"sl_si\": \"Slovenian\", \"sn_zw\": \"Shona\", \"so_so\": \"Somali\", \"sr_rs\": \"Serbian\", \"sv_se\": \"Swedish\", \"sw_ke\": \"Swahili\", \"ta_in\": \"Tamil\", \"te_in\": \"Telugu\", \"tg_tj\": \"Tajik\", \"th_th\": \"Thai\", \"tr_tr\": \"Turkish\", \"uk_ua\": \"Ukrainian\", \"ur_pk\": \"Urdu\", \"uz_uz\": \"Uzbek\", \"vi_vn\": \"Vietnamese\", \"yo_ng\": \"Yoruba\"}\n",
    "selection = widgets.Dropdown(\n",
    "    options=[(\"Select language\", None), (\"----------\", None)] + sorted([(f\"{v} ({k})\", k) for k, v in languages.items()]),\n",
    "    value=\"en_us\",\n",
    "    description='Language:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "lang = selection.value\n",
    "language = languages[lang]\n",
    "\n",
    "assert lang is not None, \"Please select a language\"\n",
    "print(f\"Selected language: {language} ({lang})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url: str, target_path: str):\n",
    "    with urllib.request.urlopen(url) as source, open(target_path, \"wb\") as output:\n",
    "        with tqdm(total=int(source.info().get(\"Content-Length\")), ncols=80, unit='iB', unit_scale=True, unit_divisor=1024) as loop:\n",
    "            while True:\n",
    "                buffer = source.read(8192)\n",
    "                if not buffer:\n",
    "                    break\n",
    "\n",
    "                output.write(buffer)\n",
    "                loop.update(len(buffer))\n",
    "\n",
    "\n",
    "class Fleurs(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    A simple class to wrap Fleurs and subsample a portion of the dataset as needed.\n",
    "    \"\"\"\n",
    "    def __init__(self, lang, split=\"test\", subsample_rate=1, device=DEVICE):\n",
    "        url = f\"https://storage.googleapis.com/xtreme_translations/FLEURS102/{lang}.tar.gz\"\n",
    "        tar_path = os.path.expanduser(f\"~/.cache/fleurs/{lang}.tgz\")\n",
    "        os.makedirs(os.path.dirname(tar_path), exist_ok=True)\n",
    "\n",
    "        if not os.path.exists(tar_path):\n",
    "            download(url, tar_path)\n",
    "\n",
    "        all_audio = {}\n",
    "        with tarfile.open(tar_path, \"r:gz\") as tar:\n",
    "            for member in tar.getmembers():\n",
    "                name = member.name\n",
    "                if name.endswith(f\"{split}.tsv\"):\n",
    "                    labels = pd.read_table(tar.extractfile(member), names=(\"id\", \"file_name\", \"raw_transcription\", \"transcription\", \"_\", \"num_samples\", \"gender\"))\n",
    "\n",
    "                if f\"/{split}/\" in name and name.endswith(\".wav\"):\n",
    "                    audio_bytes = tar.extractfile(member).read()\n",
    "                    all_audio[os.path.basename(name)] = wavfile.read(io.BytesIO(audio_bytes))[1]                    \n",
    "\n",
    "        self.labels = labels.to_dict(\"records\")[::subsample_rate]\n",
    "        self.all_audio = all_audio\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        record = self.labels[item]\n",
    "        audio = torch.from_numpy(self.all_audio[record[\"file_name\"]].copy())\n",
    "        text = record[\"transcription\"]\n",
    "        \n",
    "        return (audio, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fee6432466b496c841e8746c11410dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                              | 0.00/1.72G [00:00<?, ?iB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = Fleurs(lang, subsample_rate=100)  # subsample 10% of the dataset for a quick demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomjoy/Documents/GitHub/atmos-server/whisper/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is multilingual and has 71,825,920 parameters.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b0872e2c3e4ba9af15788fb233bd58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomjoy/Documents/GitHub/atmos-server/whisper/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "from whisper import whisper\n",
    "whisper.model.MultiHeadAttention.use_sdpa = False\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "print(\n",
    "    f\"Model is {'multilingual' if model.is_multilingual else 'English-only'} \"\n",
    "    f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,} parameters.\"\n",
    ")\n",
    "\n",
    "options = dict(language=language, beam_size=5, best_of=5)\n",
    "transcribe_options = dict(task=\"transcribe\", **options)\n",
    "translate_options = dict(task=\"translate\", **options)\n",
    "\n",
    "references = []\n",
    "transcriptions = []\n",
    "translations = []\n",
    "\n",
    "for audio, text in tqdm(dataset):\n",
    "    transcription = model.transcribe(audio, **transcribe_options)[\"text\"]\n",
    "    translation = model.transcribe(audio, **translate_options)[\"text\"]\n",
    "    \n",
    "    transcriptions.append(transcription)\n",
    "    translations.append(translation)\n",
    "    references.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>transcription</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unfortunately studying traffic flow is difficult because driver behavior cannot be predicted with one-hundred percent certainty</td>\n",
       "      <td>Unfortunately, stunning traffic flow is difficult because driver behavior cannot be predicted with 100% certainty.</td>\n",
       "      <td>Unfortunately, stunning traffic flow is difficult because driver behavior cannot be predicted with 100% certainty.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dr malar balasubramanian 29 was found in blue ash ohio a suburb approximately 15 miles north of cincinnati lying on the ground beside the road in a t-shirt and underwear in an apparently heavily medicated state</td>\n",
       "      <td>Dr. Mala Bala Subramanian 29 was found in Blue Ash, Ohio, a suburb approximately 15 miles north of Cincinnati, lying on the ground beside the road in a t-shirt and underwear in an apparently heavily medicated state.</td>\n",
       "      <td>Dr. Mala Bala Subramanian 29 was found in Blue Ash, Ohio, a suburb approximately 15 miles north of Cincinnati, lying on the ground beside the road in a t-shirt and underwear in an apparently heavily medicated state.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>goats seem to have been first domesticated roughly 10,000 years ago in the zagros mountains of iran</td>\n",
       "      <td>Goats seemed to have been first domesticated roughly 10,000 years ago in the Zagros Mountains of Iran.</td>\n",
       "      <td>Goats seemed to have been first domesticated roughly 10,000 years ago in the Zagros Mountains of Iran.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the 25 dunlap broadsides still known to exist are the oldest surviving copies of the document the original handwritten copy has not survived</td>\n",
       "      <td>The 25 Dunlap Broadside's still known to exist are the oldest surviving copies of the document. The original handwritten copy has not survived.</td>\n",
       "      <td>The 25 Dunlap broadsides still known to exist are the oldest surviving copies of the document. The original handwritten copy has not survived.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>elements like calcium and potassium are considered metals of course there are also metals like silver and gold</td>\n",
       "      <td>Elements like calcium and potassium are considered metals, of course there are also metals like silver and gold.</td>\n",
       "      <td>Elements like calcium and potassium are considered metals, of course there are also metals like silver and gold.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the ph level is indicated by the amount of hydrogen the h in ph ions in the tested chemical</td>\n",
       "      <td>The pH levels level is indicated by the amount of hydrogen, the age and pH, ions in the tested chemical.</td>\n",
       "      <td>The pH levels level is indicated by the amount of hydrogen the age in pH ions in the tested chemical.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aristotle a philosopher theorised that everything is made up of a mixture of one or more of four elements they were earth water air and fire</td>\n",
       "      <td>Aristotle, philosopher, theorized that everything is made up of a mixture of one or more four elements. They were earth, water, air, and fire.</td>\n",
       "      <td>Aristotle, philosopher, theorized that everything is made up of a mixture of one or more four elements that were earth, water, air, and fire.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                            reference  \\\n",
       "0                                                                                     unfortunately studying traffic flow is difficult because driver behavior cannot be predicted with one-hundred percent certainty   \n",
       "1  dr malar balasubramanian 29 was found in blue ash ohio a suburb approximately 15 miles north of cincinnati lying on the ground beside the road in a t-shirt and underwear in an apparently heavily medicated state   \n",
       "2                                                                                                                 goats seem to have been first domesticated roughly 10,000 years ago in the zagros mountains of iran   \n",
       "3                                                                        the 25 dunlap broadsides still known to exist are the oldest surviving copies of the document the original handwritten copy has not survived   \n",
       "4                                                                                                      elements like calcium and potassium are considered metals of course there are also metals like silver and gold   \n",
       "5                                                                                                                         the ph level is indicated by the amount of hydrogen the h in ph ions in the tested chemical   \n",
       "6                                                                        aristotle a philosopher theorised that everything is made up of a mixture of one or more of four elements they were earth water air and fire   \n",
       "\n",
       "                                                                                                                                                                                                              transcription  \\\n",
       "0                                                                                                        Unfortunately, stunning traffic flow is difficult because driver behavior cannot be predicted with 100% certainty.   \n",
       "1   Dr. Mala Bala Subramanian 29 was found in Blue Ash, Ohio, a suburb approximately 15 miles north of Cincinnati, lying on the ground beside the road in a t-shirt and underwear in an apparently heavily medicated state.   \n",
       "2                                                                                                                    Goats seemed to have been first domesticated roughly 10,000 years ago in the Zagros Mountains of Iran.   \n",
       "3                                                                           The 25 Dunlap Broadside's still known to exist are the oldest surviving copies of the document. The original handwritten copy has not survived.   \n",
       "4                                                                                                          Elements like calcium and potassium are considered metals, of course there are also metals like silver and gold.   \n",
       "5                                                                                                                  The pH levels level is indicated by the amount of hydrogen, the age and pH, ions in the tested chemical.   \n",
       "6                                                                            Aristotle, philosopher, theorized that everything is made up of a mixture of one or more four elements. They were earth, water, air, and fire.   \n",
       "\n",
       "                                                                                                                                                                                                                translation  \n",
       "0                                                                                                        Unfortunately, stunning traffic flow is difficult because driver behavior cannot be predicted with 100% certainty.  \n",
       "1   Dr. Mala Bala Subramanian 29 was found in Blue Ash, Ohio, a suburb approximately 15 miles north of Cincinnati, lying on the ground beside the road in a t-shirt and underwear in an apparently heavily medicated state.  \n",
       "2                                                                                                                    Goats seemed to have been first domesticated roughly 10,000 years ago in the Zagros Mountains of Iran.  \n",
       "3                                                                            The 25 Dunlap broadsides still known to exist are the oldest surviving copies of the document. The original handwritten copy has not survived.  \n",
       "4                                                                                                          Elements like calcium and potassium are considered metals, of course there are also metals like silver and gold.  \n",
       "5                                                                                                                     The pH levels level is indicated by the amount of hydrogen the age in pH ions in the tested chemical.  \n",
       "6                                                                             Aristotle, philosopher, theorized that everything is made up of a mixture of one or more four elements that were earth, water, air, and fire.  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(dict(reference=references, transcription=transcriptions, translation=translations))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from whisper.tokenizer import get_tokenizer\n",
    "from dtw import dtw\n",
    "from scipy.ndimage import median_filter\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_SAMPLES_PER_TOKEN = whisper.audio.HOP_LENGTH * 2\n",
    "AUDIO_TIME_PER_TOKEN = AUDIO_SAMPLES_PER_TOKEN / whisper.audio.SAMPLE_RATE\n",
    "\n",
    "medfilt_width = 7\n",
    "qk_scale = 1.0\n",
    "\n",
    "tokenizer = get_tokenizer(model.is_multilingual, language=languages[lang])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a2c8cdaef24596a37c59c516e45899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                              | 0.00/14.2M [00:00<?, ?iB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This part downloads a repackaged version of the Noto Sans font (either CJK or non-CJK)\n",
    "# to render various languages in Matplotlib figures.\n",
    "\n",
    "if languages[lang] in {\"Chinese\", \"Japanese\", \"Korean\"}:\n",
    "    font = \"GoNotoCJKCore.ttf\"\n",
    "else:\n",
    "    font = \"GoNotoCurrent.ttf\"\n",
    "\n",
    "font_release = \"https://github.com/satbyy/go-noto-universal/releases/download/v5.2\"\n",
    "if not os.path.exists(font):\n",
    "    download(f\"{font_release}/{font}\", font)\n",
    "\n",
    "prop = fm.FontProperties(fname=font)\n",
    "props = {'fontproperties': prop}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tokens_on_unicode(tokens: torch.Tensor):\n",
    "    words = []\n",
    "    word_tokens = []\n",
    "    current_tokens = []\n",
    "    \n",
    "    for token in tokens.tolist():\n",
    "        current_tokens.append(token)\n",
    "        decoded = tokenizer.decode_with_timestamps(current_tokens)\n",
    "        if \"\\ufffd\" not in decoded:\n",
    "            words.append(decoded)\n",
    "            word_tokens.append(current_tokens)\n",
    "            current_tokens = []\n",
    "    \n",
    "    return words, word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tokens_on_spaces(tokens: torch.Tensor):\n",
    "    subwords, subword_tokens_list = split_tokens_on_unicode(tokens)\n",
    "    words = []\n",
    "    word_tokens = []\n",
    "    \n",
    "    for subword, subword_tokens in zip(subwords, subword_tokens_list):\n",
    "        special = subword_tokens[0] >= tokenizer.eot\n",
    "        with_space = subword.startswith(\" \")\n",
    "        punctuation = subword.strip() in string.punctuation\n",
    "        if special or with_space or punctuation:\n",
    "            words.append(subword)\n",
    "            word_tokens.append(subword_tokens)\n",
    "        else:\n",
    "            words[-1] = words[-1] + subword\n",
    "            word_tokens[-1].extend(subword_tokens)\n",
    "    \n",
    "    return words, word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if languages[lang] in {\"Chinese\", \"Japanese\", \"Thai\", \"Lao\", \"Myanmar\"}:\n",
    "    # These languages don't typically use spaces, so it is difficult to split words\n",
    "    # without morpheme analysis. Here, we instead split words at any\n",
    "    # position where the tokens are decoded as valid unicode points\n",
    "    split_tokens = split_tokens_on_unicode\n",
    "else:\n",
    "    split_tokens = split_tokens_on_spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install hooks on the cross attention layers to retrieve the attention weights\n",
    "QKs = [None] * model.dims.n_text_layer\n",
    "\n",
    "# Define the hook function explicitly\n",
    "def save_attention_weights(module, input, output, index):\n",
    "    QKs[index] = output[-1]  # Save the attention weights for each layer\n",
    "\n",
    "# Register the forward hooks explicitly\n",
    "for i, block in enumerate(model.decoder.blocks):\n",
    "    block.cross_attn.register_forward_hook(lambda module, input, output, i=i: save_attention_weights(module, input, output, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Unfortunately, stunning traffic flow is difficult because driver behavior cannot be predicted with 100% certainty.\n",
      "torch.Size([80, 3000]) torch.Size([24])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unfortunately</td>\n",
       "      <td>2.08</td>\n",
       "      <td>2.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stunning</td>\n",
       "      <td>2.62</td>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>traffic</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flow</td>\n",
       "      <td>3.46</td>\n",
       "      <td>3.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>3.66</td>\n",
       "      <td>4.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>difficult</td>\n",
       "      <td>4.24</td>\n",
       "      <td>4.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>because</td>\n",
       "      <td>4.76</td>\n",
       "      <td>5.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>driver</td>\n",
       "      <td>5.14</td>\n",
       "      <td>5.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>behavior</td>\n",
       "      <td>5.84</td>\n",
       "      <td>6.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cannot</td>\n",
       "      <td>6.22</td>\n",
       "      <td>6.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>be</td>\n",
       "      <td>6.52</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>predicted</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>with</td>\n",
       "      <td>7.70</td>\n",
       "      <td>8.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100</td>\n",
       "      <td>8.32</td>\n",
       "      <td>9.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>%</td>\n",
       "      <td>9.00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>certainty</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word  begin    end\n",
       "0    Unfortunately   2.08   2.14\n",
       "1         stunning   2.62   3.10\n",
       "2          traffic   3.10   3.46\n",
       "3             flow   3.46   3.66\n",
       "4               is   3.66   4.24\n",
       "5        difficult   4.24   4.76\n",
       "6          because   4.76   5.14\n",
       "7           driver   5.14   5.84\n",
       "8         behavior   5.84   6.22\n",
       "9           cannot   6.22   6.52\n",
       "10              be   6.52   7.00\n",
       "11       predicted   7.00   7.70\n",
       "12            with   7.70   8.32\n",
       "13             100   8.32   9.00\n",
       "14               %   9.00  10.00\n",
       "15       certainty  10.00  10.38"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for the first 10 examples in the dataset\n",
    "for (audio, label), transcription in zip(dataset, transcriptions):\n",
    "    print(transcription)\n",
    "  \n",
    "    duration = len(audio)\n",
    "    mel = whisper.log_mel_spectrogram(whisper.pad_or_trim(audio))\n",
    "    tokens = torch.tensor(\n",
    "        [\n",
    "            *tokenizer.sot_sequence,\n",
    "            tokenizer.timestamp_begin,\n",
    "        ] + tokenizer.encode(transcription) + [\n",
    "            tokenizer.timestamp_begin + duration // AUDIO_SAMPLES_PER_TOKEN,\n",
    "            tokenizer.eot,\n",
    "        ]\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        logits = model(mel.unsqueeze(0), tokens.unsqueeze(0))\n",
    "\n",
    "    print(mel.shape, tokens.shape)\n",
    "    weights = torch.cat(QKs)  # layers * heads * tokens * frames    \n",
    "    weights = weights[:, :, :, : duration // AUDIO_SAMPLES_PER_TOKEN].cpu()\n",
    "    weights = median_filter(weights, (1, 1, 1, medfilt_width))\n",
    "    weights = torch.tensor(weights * qk_scale).softmax(dim=-1)\n",
    "    \n",
    "    w = weights / weights.norm(dim=-2, keepdim=True)\n",
    "    matrix = w[-6:].mean(axis=(0, 1))\n",
    "\n",
    "    alignment = dtw(-matrix.double().numpy())\n",
    "\n",
    "    jumps = np.pad(np.diff(alignment.index1s), (1, 0), constant_values=1).astype(bool)\n",
    "    jump_times = alignment.index2s[jumps] * AUDIO_TIME_PER_TOKEN\n",
    "    words, word_tokens = split_tokens(tokens)\n",
    "\n",
    "    # # display the normalized attention weights and the alignment\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(matrix, aspect=\"auto\")\n",
    "    plt.plot(alignment.index2s, alignment.index1s, color=\"red\")\n",
    "\n",
    "    xticks = np.arange(0, matrix.shape[1], 1 / AUDIO_TIME_PER_TOKEN)\n",
    "    xticklabels = (xticks * AUDIO_TIME_PER_TOKEN).round().astype(np.int32) \n",
    "    plt.xticks(xticks, xticklabels)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    \n",
    "    # display tokens and words as tick labels\n",
    "    ylims = plt.gca().get_ylim()\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.tick_params('both', length=0, width=0, which='minor', pad=6)\n",
    "\n",
    "    ax.yaxis.set_ticks_position(\"left\")\n",
    "    ax.yaxis.set_label_position(\"left\")\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_ylim(ylims)\n",
    "\n",
    "    major_ticks = [-0.5]\n",
    "    minor_ticks = []\n",
    "    current_y = 0\n",
    "    \n",
    "    for word, word_token in zip(words, word_tokens):\n",
    "        minor_ticks.append(current_y + len(word_token) / 2 - 0.5)\n",
    "        current_y += len(word_token)\n",
    "        major_ticks.append(current_y - 0.5)\n",
    "        \n",
    "    ax.yaxis.set_minor_locator(ticker.FixedLocator(minor_ticks))\n",
    "    ax.yaxis.set_minor_formatter(ticker.FixedFormatter(words))\n",
    "    ax.set_yticks(major_ticks)\n",
    "    ax.yaxis.set_major_formatter(ticker.NullFormatter())\n",
    "    \n",
    "    for label in ax.get_yminorticklabels():\n",
    "        label.set_fontproperties(prop)\n",
    "\n",
    "    plt.ylabel(\"Words\")\n",
    "    plt.show()\n",
    "\n",
    "    # display the word-level timestamps in a table\n",
    "    word_boundaries = np.pad(np.cumsum([len(t) for t in word_tokens[:-1]]), (1, 0))\n",
    "    begin_times = jump_times[word_boundaries[:-1]]\n",
    "    end_times = jump_times[word_boundaries[1:]]\n",
    "\n",
    "    data = [\n",
    "        dict(word=word, begin=begin, end=end)\n",
    "        for word, begin, end in zip(words[:-1], begin_times, end_times)\n",
    "        if not word.startswith(\"<|\") and word.strip() not in \".,!?、。\"\n",
    "    ]\n",
    "\n",
    "    display(pd.DataFrame(data))\n",
    "    display(HTML(\"<hr>\"))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_speech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
